FEATURE_COLS = ["m-0", "m-1", "m-2", "ma3"]

def ensure_lags(df):
    """
    Ensure lag features exist for each key. Works in-place on a copy.
    Input df: pandas DataFrame with columns ['key','periods','so_nw_ct'].
    Produces m-0 (lag 3), m-1 (lag 4), m-2 (lag 5), ma3.
    """
    df = df.copy()
    # make sure periods sort properly
    df = df.sort_values(["key", "periods"])
    # compute lags per key
    df["m-0"] = df.groupby("key")["so_nw_ct"].shift(3)
    df["m-1"] = df.groupby("key")["so_nw_ct"].shift(4)
    df["m-2"] = df.groupby("key")["so_nw_ct"].shift(5)
    df["ma3"] = df[["m-0","m-1","m-2"]].mean(axis=1)
    # fill NaN with 0 to keep shapes consistent (you can choose np.nan instead)
    df[["m-0","m-1","m-2","ma3"]] = df[["m-0","m-1","m-2","ma3"]].fillna(0.0)
    return df
------------------------------------------------------------------------------------------------
def run_zone_forecasting_lr_experiment(job):
    """
    job: tuple (train_df_pandas, test_period (datetime), train_window_months or None, oversample_cfg)
    oversample_cfg: None or dict with keys:
       {"strategy": "weight" or "duplicate", "pos_fraction": 0.5, "weight_factor": 5}
    Returns pandas.DataFrame of results (one-row per key for that test_period)
    """
    train_df, test_period, train_window_months, oversample_cfg, min_train_size = job

    max_train_period = (test_period - relativedelta(months=3)).strftime("%Y %m")
    test_period_str = test_period.strftime("%Y %m")

    # base filter: only <= max_train_period (same as your baseline)
    curr_train_df = train_df.loc[train_df["periods"] <= max_train_period].copy()
    curr_test_df = train_df.loc[train_df["periods"] == test_period_str].copy()

    # apply rolling window if requested (train_window_months is int)
    if train_window_months is not None:
        # convert to datetime for robust comparison
        curr_train_df["period_dt"] = pd.to_datetime(curr_train_df["periods"].str.replace(" ", "-"))
        max_train_dt = pd.to_datetime(max_train_period.replace(" ", "-"))
        cutoff_dt = max_train_dt - relativedelta(months=train_window_months-1)
        curr_train_df = curr_train_df.loc[curr_train_df["period_dt"] >= cutoff_dt].drop(columns=["period_dt"])

    # ensure lags exist (so we don't depend on external precomputed features)
    curr_train_df = ensure_lags(curr_train_df)
    curr_test_df = ensure_lags(curr_test_df)

    rows = []

    all_keys = np.sort(train_df["key"].unique())  # keep same domain as baseline
    for key in all_keys:
        train_k = curr_train_df.loc[curr_train_df["key"] == key].copy()
        test_k = curr_test_df.loc[curr_test_df["key"] == key].copy()

        # fallback when no training data for this key
        if len(train_k) == 0:
            rows.append({
                "key": key,
                "periods": test_period_str,
                "m-0": 0, "m-1": 0, "m-2": 0, "ma3": 0,
                "so_nw_ct": 0, "pred": 0
            })
            continue

        # fallback when no test row exists for this key
        if test_k.shape[0] == 0:
            rows.append({
                "key": key,
                "periods": test_period_str,
                "m-0": 0, "m-1": 0, "m-2": 0, "ma3": 0,
                "so_nw_ct": 0, "pred": 0
            })
            continue

        # prepare X/y
        X_train = train_k[FEATURE_COLS].astype(float)
        y_train = train_k["so_nw_ct"].astype(float)
        X_test = test_k[FEATURE_COLS].astype(float)
        y_test = test_k["so_nw_ct"].astype(float)

        # min train size check (avoid pathological OLS fit)
        if len(X_train) < min_train_size:
            rows.append({
                "key": key,
                "periods": test_period_str,
                "m-0": X_test["m-0"].iloc[0],
                "m-1": X_test["m-1"].iloc[0],
                "m-2": X_test["m-2"].iloc[0],
                "ma3": X_test["ma3"].iloc[0],
                "so_nw_ct": y_test.iloc[0],
                "pred": 0
            })
            continue

        # oversampling strategies
        sample_weight = None
        if oversample_cfg is not None:
            strat = oversample_cfg.get("strategy", "weight")
            if strat == "duplicate":
                # duplicate positive rows to reach desired fraction of positives in training
                desired_pos_frac = float(oversample_cfg.get("pos_fraction", 0.5))
                pos_mask = (y_train > 0)
                n_total = len(y_train)
                n_pos = pos_mask.sum()
                desired_pos = int(desired_pos_frac * n_total)
                if desired_pos > n_pos and n_pos > 0:
                    n_to_sample = desired_pos - n_pos
                    sampled = train_k.loc[pos_mask].sample(n=n_to_sample, replace=True, random_state=123)
                    # append sampled rows to train_k, then recompute X_train, y_train
                    train_k = pd.concat([train_k, sampled], ignore_index=True)
                    X_train = train_k[FEATURE_COLS].astype(float)
                    y_train = train_k["so_nw_ct"].astype(float)
            elif strat == "weight":
                # set sample weights that give more importance to positive rows
                weight_factor = float(oversample_cfg.get("weight_factor", 5.0))
                # weight positive rows by weight_factor, else 1.0
                sample_weight = (y_train > 0).astype(float) * (weight_factor - 1.0) + 1.0
            else:
                # unknown strategy -> ignore
                pass

        # fit linear regression with or without sample_weight
        model = LinearRegression()
        if sample_weight is None:
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
        else:
            model.fit(X_train, y_train, sample_weight=sample_weight)
            pred = model.predict(X_test)

        rows.append({
            "key": key,
            "periods": test_period_str,
            "m-0": X_test["m-0"].iloc[0],
            "m-1": X_test["m-1"].iloc[0],
            "m-2": X_test["m-2"].iloc[0],
            "ma3": X_test["ma3"].iloc[0],
            "so_nw_ct": y_test.iloc[0],
            "pred": float(pred[0]) if np.ndim(pred) else float(pred)
        })

    return pd.DataFrame(rows)
------------------------------------------------------------------------------------------------
def run_zone_forecasting_lr_experiment(job):
    """
    job: tuple (train_df_pandas, test_period (datetime), train_window_months or None, oversample_cfg)
    oversample_cfg: None or dict with keys:
       {"strategy": "weight" or "duplicate", "pos_fraction": 0.5, "weight_factor": 5}
    Returns pandas.DataFrame of results (one-row per key for that test_period)
    """
    train_df, test_period, train_window_months, oversample_cfg, min_train_size = job

    max_train_period = (test_period - relativedelta(months=3)).strftime("%Y %m")
    test_period_str = test_period.strftime("%Y %m")

    # base filter: only <= max_train_period (same as your baseline)
    curr_train_df = train_df.loc[train_df["periods"] <= max_train_period].copy()
    curr_test_df = train_df.loc[train_df["periods"] == test_period_str].copy()

    # apply rolling window if requested (train_window_months is int)
    if train_window_months is not None:
        # convert to datetime for robust comparison
        curr_train_df["period_dt"] = pd.to_datetime(curr_train_df["periods"].str.replace(" ", "-"))
        max_train_dt = pd.to_datetime(max_train_period.replace(" ", "-"))
        cutoff_dt = max_train_dt - relativedelta(months=train_window_months-1)
        curr_train_df = curr_train_df.loc[curr_train_df["period_dt"] >= cutoff_dt].drop(columns=["period_dt"])

    # ensure lags exist (so we don't depend on external precomputed features)
    curr_train_df = ensure_lags(curr_train_df)
    curr_test_df = ensure_lags(curr_test_df)

    rows = []

    all_keys = np.sort(train_df["key"].unique())  # keep same domain as baseline
    for key in all_keys:
        train_k = curr_train_df.loc[curr_train_df["key"] == key].copy()
        test_k = curr_test_df.loc[curr_test_df["key"] == key].copy()

        # fallback when no training data for this key
        if len(train_k) == 0:
            rows.append({
                "key": key,
                "periods": test_period_str,
                "m-0": 0, "m-1": 0, "m-2": 0, "ma3": 0,
                "so_nw_ct": 0, "pred": 0
            })
            continue

        # fallback when no test row exists for this key
        if test_k.shape[0] == 0:
            rows.append({
                "key": key,
                "periods": test_period_str,
                "m-0": 0, "m-1": 0, "m-2": 0, "ma3": 0,
                "so_nw_ct": 0, "pred": 0
            })
            continue

        # prepare X/y
        X_train = train_k[FEATURE_COLS].astype(float)
        y_train = train_k["so_nw_ct"].astype(float)
        X_test = test_k[FEATURE_COLS].astype(float)
        y_test = test_k["so_nw_ct"].astype(float)

        # min train size check (avoid pathological OLS fit)
        if len(X_train) < min_train_size:
            rows.append({
                "key": key,
                "periods": test_period_str,
                "m-0": X_test["m-0"].iloc[0],
                "m-1": X_test["m-1"].iloc[0],
                "m-2": X_test["m-2"].iloc[0],
                "ma3": X_test["ma3"].iloc[0],
                "so_nw_ct": y_test.iloc[0],
                "pred": 0
            })
            continue

        # oversampling strategies
        sample_weight = None
        if oversample_cfg is not None:
            strat = oversample_cfg.get("strategy", "weight")
            if strat == "duplicate":
                # duplicate positive rows to reach desired fraction of positives in training
                desired_pos_frac = float(oversample_cfg.get("pos_fraction", 0.5))
                pos_mask = (y_train > 0)
                n_total = len(y_train)
                n_pos = pos_mask.sum()
                desired_pos = int(desired_pos_frac * n_total)
                if desired_pos > n_pos and n_pos > 0:
                    n_to_sample = desired_pos - n_pos
                    sampled = train_k.loc[pos_mask].sample(n=n_to_sample, replace=True, random_state=123)
                    # append sampled rows to train_k, then recompute X_train, y_train
                    train_k = pd.concat([train_k, sampled], ignore_index=True)
                    X_train = train_k[FEATURE_COLS].astype(float)
                    y_train = train_k["so_nw_ct"].astype(float)
            elif strat == "weight":
                # set sample weights that give more importance to positive rows
                weight_factor = float(oversample_cfg.get("weight_factor", 5.0))
                # weight positive rows by weight_factor, else 1.0
                sample_weight = (y_train > 0).astype(float) * (weight_factor - 1.0) + 1.0
            else:
                # unknown strategy -> ignore
                pass

        # fit linear regression with or without sample_weight
        model = LinearRegression()
        if sample_weight is None:
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
        else:
            model.fit(X_train, y_train, sample_weight=sample_weight)
            pred = model.predict(X_test)

        rows.append({
            "key": key,
            "periods": test_period_str,
            "m-0": X_test["m-0"].iloc[0],
            "m-1": X_test["m-1"].iloc[0],
            "m-2": X_test["m-2"].iloc[0],
            "ma3": X_test["ma3"].iloc[0],
            "so_nw_ct": y_test.iloc[0],
            "pred": float(pred[0]) if np.ndim(pred) else float(pred)
        })

    return pd.DataFrame(rows)
------------------------------------------------------------------------------------------------
def run_experiment_over_zones(
    so_fcst_df,             # polars or pandas? use pandas for this runner
    start_test_period,
    test_period_count=6,
    train_window_months=None,
    oversample_cfg=None,
    min_train_size=3,
    save_prefix="LR_exp"
):
    """
    so_fcst_df: pandas DataFrame with 'zone','key','periods','so_nw_ct' columns.
    start_test_period: datetime.datetime or pd.Timestamp e.g. datetime(2025,7,1)
    """
    # ensure pandas DataFrame
    if not isinstance(so_fcst_df, pd.DataFrame):
        df_pol = so_fcst_df
        so_fcst_df = df_pol.to_pandas()

    # ensure lag columns are present globally (not required but faster)
    so_fcst_df = ensure_lags(so_fcst_df)

    # build test_period_list same as your baseline logic
    test_period_list = [ start_test_period + relativedelta(months=i) for i in range(test_period_count) ]

    jobs = []
    for zone in np.sort(so_fcst_df["zone"].unique()):
        zone_df = so_fcst_df.loc[so_fcst_df["zone"] == zone].copy()
        # drop zone column as your baseline did
        zone_df = zone_df.drop(columns=["zone"], errors="ignore")
        for test_period in test_period_list:
            jobs.append((zone_df, test_period, train_window_months, oversample_cfg, min_train_size))

    # run serially (simple)
    parts = []
    for job in jobs:
        res = run_zone_forecasting_lr_experiment(job)
        parts.append(res)

    if len(parts) == 0:
        final = pd.DataFrame()
    else:
        final = pd.concat(parts, ignore_index=True)

    # compute mape etc using your existing polars logic or simple pandas
    # Convert to polars and reuse your build_performance if you prefer.
    import polars as pl
    rs_with_error = pl.from_pandas(final).with_columns(
        re = pl.col("pred") - pl.col("so_nw_ct"),
        ae = (pl.col("pred") - pl.col("so_nw_ct")).abs()
    ).with_columns(
        mape = pl.when(pl.col("so_nw_ct") > 0).then(pl.col("ae")/pl.col("so_nw_ct")).otherwise(1)
    ).with_columns(
        mape = pl.when(pl.col("mape") > 1).then(1).otherwise(pl.col("mape"))
    )

    perf = rs_with_error.pivot(
        on="periods", index="key", values="mape", aggregate_function="sum", sort_columns=True
    ).with_columns(
        mape_avg = pl.col(rs_with_error.columns).exclude("key").mean_horizontal()  # or use earlier safe form
    )

    # save
    rs_file = f"{save_prefix}_rs.csv"
    perf_file = f"{save_prefix}_perf.csv"
    rs_with_error.write_csv(rs_file)
    perf.write_csv(perf_file)
    print("Saved:", rs_file, perf_file)
    return rs_with_error, perf
------------------------------------------------------------------------------------------------
start_test_period = datetime(2025, 7, 1)
so_pd = so_fcst_df.to_pandas() if hasattr(so_fcst_df, "to_pandas") else so_fcst_df

# 1) baseline: you already have baseline, but if you want to run via new runner with no window/no oversample:
rs_base, perf_base = run_experiment_over_zones(so_pd, start_test_period,
                                              test_period_count=6,
                                              train_window_months=None,
                                              oversample_cfg=None,
                                              save_prefix="LR_baseline")

# 2) 1-year only
rs_1y, perf_1y = run_experiment_over_zones(so_pd, start_test_period,
                                          test_period_count=6,
                                          train_window_months=12,
                                          oversample_cfg=None,
                                          save_prefix="LR_1yr")

# 3) oversampling only (use weighting strategy â€” recommended)
oversample_cfg_weight = {"strategy":"weight", "weight_factor":5.0}
rs_os, perf_os = run_experiment_over_zones(so_pd, start_test_period,
                                          test_period_count=6,
                                          train_window_months=None,
                                          oversample_cfg=oversample_cfg_weight,
                                          save_prefix="LR_oversample")

# 4) 1-year + oversample (weight)
rs_1y_os, perf_1y_os = run_experiment_over_zones(so_pd, start_test_period,
                                                test_period_count=6,
                                                train_window_months=12,
                                                oversample_cfg=oversample_cfg_weight,
                                                save_prefix="LR_1yr_oversample")
------------------------------------------------------------------------------------------------
perf_base = perf_base
perf_1y = perf_1y
perf_os = perf_os
perf_1y_os = perf_1y_os

# add labels
perf_base = perf_base.with_columns(model=pl.lit("LR_baseline"))
perf_1y = perf_1y.with_columns(model=pl.lit("LR_1yr"))
perf_os = perf_os.with_columns(model=pl.lit("LR_os"))
perf_1y_os = perf_1y_os.with_columns(model=pl.lit("LR_1yr_os"))

comp = pl.concat([perf_base, perf_1y, perf_os, perf_1y_os])
summary = comp.group_by("model").agg(pl.mean("mape_avg").alias("mean_mape"), pl.median("mape_avg").alias("median_mape"))
display(summary)
