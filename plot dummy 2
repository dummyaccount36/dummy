plt.rcParams["figure.figsize"] = (12,4)
plt.rcParams["figure.dpi"] = 120

RESULTS_DIR = Path("results")


rs_rf_all = pd.read_csv(
    RESULTS_DIR / "rs_with_error_RF_all.csv"
)

rs_rf_all.head()



rs_rf_all["period_dt"] = pd.to_datetime(
    rs_rf_all["periods"].str.replace(" ", "-") + "-01",
    format="%Y-%m-%d"
)

rs_rf_all = rs_rf_all.sort_values(["key", "period_dt"])



df_k = rs_rf_all[rs_rf_all["key"] == example_key]

plt.figure()
plt.plot(df_k["period_dt"], df_k["so_nw_ct"], marker="o", label="Actual")
plt.plot(df_k["period_dt"], df_k["pred"], marker="o", linestyle="--", label="Forecast")

plt.title(f"RF Forecast vs Actual\n{example_key}")
plt.xlabel("Period")
plt.ylabel("SO Quantity")
plt.legend()
plt.tight_layout()
plt.show()







top_keys = (
    rs_rf_all[rs_rf_all["periods"].str.contains("2025")]
    .groupby("key")["so_nw_ct"]
    .sum()
    .sort_values(ascending=False)
    .head(6)
    .index
)




fig, axes = plt.subplots(3, 2, figsize=(14,9), sharex=True)
axes = axes.flatten()

for ax, key in zip(axes, top_keys):
    d = rs_rf_all[rs_rf_all["key"] == key]
    ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual")
    ax.plot(d["period_dt"], d["pred"], marker="o", linestyle="--", label="Forecast")
    ax.set_title(key)
    ax.legend(fontsize=8)

plt.tight_layout()
plt.show()






zone_keys = rs_rf_all[
    rs_rf_all["key"].str.startswith("ZONE02B")
]["key"].unique()[:4]




fig, axes = plt.subplots(2, 2, figsize=(14,7), sharex=True)
axes = axes.flatten()

for ax, key in zip(axes, zone_keys):
    d = rs_rf_all[rs_rf_all["key"] == key]
    ax.plot(d["period_dt"], d["so_nw_ct"], label="Actual")
    ax.plot(d["period_dt"], d["pred"], linestyle="--", label="Forecast")
    ax.set_title(key)
    ax.legend(fontsize=8)

plt.tight_layout()
plt.show()





plt.figure()
sns.lineplot(
    data=rs_rf_all[rs_rf_all["periods"].str.contains("2025")],
    x="period_dt",
    y="mape",
    estimator="mean"
)
plt.title("Average MAPE Over Time (RF)")
plt.ylabel("MAPE")
plt.xlabel("Period")
plt.tight_layout()
plt.show()






rs_lr_all = pd.read_csv(RESULTS_DIR / "rs_with_error_LR_all.csv")
rs_lr_all["period_dt"] = pd.to_datetime(
    rs_lr_all["periods"].str.replace(" ", "-") + "-01"
)

d_rf = rs_rf_all[rs_rf_all["key"] == example_key]
d_lr = rs_lr_all[rs_lr_all["key"] == example_key]

plt.figure()
plt.plot(d_rf["period_dt"], d_rf["so_nw_ct"], label="Actual", color="black")
plt.plot(d_rf["period_dt"], d_rf["pred"], "--", label="RF")
plt.plot(d_lr["period_dt"], d_lr["pred"], "--", label="LR")






rs_rf = pd.read_csv(RESULTS_DIR / "rs_with_error_RF_all.csv")
rs_lr = pd.read_csv(RESULTS_DIR / "rs_with_error_LR_all.csv")

# normalize column names if necessary (safe guard)
for df in (rs_rf, rs_lr):
    if "periods" not in df.columns and "period" in df.columns:
        df.rename(columns={"period":"periods"}, inplace=True)

# create period datetime
for df in (rs_rf, rs_lr):
    df["period_dt"] = pd.to_datetime(df["periods"].str.replace(" ", "-") + "-01", format="%Y-%m-%d", errors="coerce")




# remove rows where so_nw_ct is zero or NaN (these were placeholders)
rs_rf_nonzero = rs_rf[rs_rf["so_nw_ct"].notnull() & (rs_rf["so_nw_ct"] != 0)].copy()
rs_lr_nonzero = rs_lr[rs_lr["so_nw_ct"].notnull() & (rs_lr["so_nw_ct"] != 0)].copy()

# create zone column by splitting key (first element before underscore)
for df in (rs_rf_nonzero, rs_lr_nonzero):
    df["zone"] = df["key"].astype(str).str.split("_").str.get(0)




print("RF nonzero rows:", len(rs_rf_nonzero))
print("LR nonzero rows:", len(rs_lr_nonzero))

# restrict to 2025 when finding top zones (makes sense for your analysis)
rf_2025 = rs_rf_nonzero[rs_rf_nonzero["periods"].str.contains("2025", na=False)]
zone_sales = rf_2025.groupby("zone")["so_nw_ct"].sum().sort_values(ascending=False)
zone_sales.head(10)



n = 4  # change if you want more zones
top_zones = zone_sales.head(n).index.tolist()
top_zones




def agg_zone(df, model_label):
    g = df.groupby(["zone", "period_dt"], as_index=False).agg({
        "so_nw_ct": "sum",
        "pred": "sum"
    })
    g = g.rename(columns={"pred": f"pred_{model_label}", "so_nw_ct": "so_nw_ct"})
    return g

agg_rf = agg_zone(rs_rf_nonzero, "RF")
agg_lr = agg_zone(rs_lr_nonzero, "LR")

# merge RF+LR aggregates (inner join on zone+period_dt)
agg_all = agg_rf.merge(agg_lr, on=["zone", "period_dt"], how="outer", suffixes=("_rf", "_lr"))
# ensure sorted
agg_all = agg_all.sort_values(["zone", "period_dt"]).reset_index(drop=True)

# quick check
agg_all.head()




zones = top_zones   # selected zones
cols = 2
rows = int(np.ceil(len(zones) / cols))
fig, axes = plt.subplots(rows, cols, figsize=(14, 4 * rows), sharex=True)
axes = axes.flatten()

for ax_idx, zone in enumerate(zones):
    ax = axes[ax_idx]
    d = agg_all[agg_all["zone"] == zone].sort_values("period_dt")
    if d.empty:
        ax.text(0.5, 0.5, f"No data for {zone}", ha="center")
        continue
    ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual (sum)")
    ax.plot(d["period_dt"], d["pred_RF"], marker="o", linestyle="--", label="RF Pred (sum)")
    ax.set_title(zone)
    ax.set_ylabel("SO quantity (sum)")
    ax.legend(fontsize=8)
    ax.grid(alpha=0.2)

# hide unused axes
for j in range(len(zones), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()





zones = top_zones
cols = 2
rows = int(np.ceil(len(zones) / cols))
fig, axes = plt.subplots(rows, cols, figsize=(14, 4 * rows), sharex=True)
axes = axes.flatten()

for ax_idx, zone in enumerate(zones):
    ax = axes[ax_idx]
    d = agg_all[agg_all["zone"] == zone].sort_values("period_dt")
    if d.empty:
        ax.text(0.5, 0.5, f"No data for {zone}", ha="center")
        continue
    ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual (sum)", color="black")
    if "pred_RF" in d.columns:
        ax.plot(d["period_dt"], d["pred_RF"], marker="o", linestyle="--", label="RF Pred (sum)")
    if "pred_LR" in d.columns:
        ax.plot(d["period_dt"], d["pred_LR"], marker="s", linestyle=":", label="LR Pred (sum)")
    ax.set_title(zone)
    ax.set_ylabel("SO quantity (sum)")
    ax.legend(fontsize=8)
    ax.grid(alpha=0.2)

for j in range(len(zones), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()








eval_rf = rs_rf.copy()
eval_lr = rs_lr.copy()

# remove zero / padded actuals
eval_rf = eval_rf[eval_rf["so_nw_ct"] > 0]
eval_lr = eval_lr[eval_lr["so_nw_ct"] > 0]




eval_rf["mape"] = (eval_rf["ae"] / eval_rf["so_nw_ct"]) * 100
eval_lr["mape"] = (eval_lr["ae"] / eval_lr["so_nw_ct"]) * 100




plt.figure(figsize=(8,4))
plt.boxplot(
    [eval_rf["mape"], eval_lr["mape"]],
    labels=["RF", "LR"],
    showfliers=False
)
plt.ylabel("MAPE (%)")
plt.title("MAPE Distribution (Non-zero Actuals)")
plt.tight_layout()
plt.show()




for df in (eval_rf, eval_lr):
    df["zone"] = df["key"].astype(str).str.split("_").str.get(0)





zone_mape_rf = (
    eval_rf.groupby("zone")["mape"]
    .mean()
    .rename("RF")
)

zone_mape_lr = (
    eval_lr.groupby("zone")["mape"]
    .mean()
    .rename("LR")
)

zone_mape = pd.concat([zone_mape_rf, zone_mape_lr], axis=1)
zone_mape = zone_mape.sort_values("RF")
zone_mape.head(10)




zone_mape.plot(
    kind="bar",
    figsize=(12,4)
)

plt.ylabel("Average MAPE (%)")
plt.title("Average MAPE by Zone (Non-zero Actuals)")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()





rs_lr = pl.read_csv("rs_with_error_LR_all.csv")
rs_rf = pl.read_csv("rs_with_error_RF_all.csv")

rs_lr = rs_lr.filter(pl.col("periods") >= "2024 01")
rs_rf = rs_rf.filter(pl.col("periods") >= "2024 01")




candidate_keys = (
    rs_lr
    .group_by("key")
    .agg(pl.col("so_nw_ct").sum().alias("total_qty"))
    .filter(pl.col("total_qty") > 0)
    .sort("total_qty", descending=True)
)

candidate_keys.head(10)




one_zone_key = candidate_keys["key"][0]
one_zone_key




df_lr_k = (
    rs_lr
    .filter(pl.col("key") == one_zone_key)
    .select(["periods", "so_nw_ct", "pred"])
    .sort("periods")
)

df_lr_k



df_rf_k = (
    rs_rf
    .filter(pl.col("key") == one_zone_key)
    .select(["periods", "so_nw_ct", "pred"])
    .sort("periods")
)

df_rf_k





df_lr_k.select(
    pl.col("so_nw_ct").describe(),
    pl.col("pred").describe()
)



-------------------------------------------------------------------------------------------------------------------------------------------

rs_lr_1 = pl.read_csv("rs_with_error_lr.csv")
rs_lr_2 = pl.read_csv("rs_with_error_lr_2.csv")

rs_lr_1.shape, rs_lr_2.shape


rs_lr_1.select(["key", "periods"]).unique().shape, \
rs_lr_2.select(["key", "periods"]).unique().shape


stats_1 = rs_lr_1.select(pl.col("pred").describe())
stats_2 = rs_lr_2.select(pl.col("pred").describe())

stats_1, stats_2


stats_compare = (
    stats_1
    .rename({"pred": "lr_run_1"})
    .with_columns(stats_2["pred"].alias("lr_run_2"))
)

stats_compare


diff = (
    rs_lr_1
    .select(["key", "periods", "pred"])
    .join(
        rs_lr_2.select(["key", "periods", "pred"]),
        on=["key", "periods"],
        suffix="_2"
    )
    .with_columns((pl.col("pred_2") - pl.col("pred")).alias("pred_diff"))
)

diff.select(pl.col("pred_diff").describe())


-------------------------------------------------------

perf_1 = pl.read_csv("perform_lr.csv")
perf_2 = pl.read_csv("perform_lr_2.csv")



perf_1.select(pl.all().exclude(pl.Utf8)).columns


perf_1.describe(), perf_2.describe()


perf_1.select(pl.col("mape").describe()), \
perf_2.select(pl.col("mape").describe())



-------------------------------------------------------------------------------------------------------------------------------------------
rs_lr = pl.read_csv("results/rs_with_error_LR_baseline.csv")



def top_n_keys_by_zone(df, zone_id, n=3):
    return (
        df
        .filter(pl.col("zone") == zone_id)
        .group_by("key")
        .agg(pl.col("so_nw_ct").sum().alias("total_qty"))
        .sort("total_qty", descending=True)
        .head(n)
        .select("key")
        .to_series()
        .to_list()
    )


top_keys_zone1 = top_n_keys_by_zone(rs_lr, zone_id=1, n=3)
top_keys_zone3 = top_n_keys_by_zone(rs_lr, zone_id=3, n=3)

top_keys_zone1, top_keys_zone3



def plot_actual_vs_lr(df, key, title):
    df_k = (
        df
        .filter(pl.col("key") == key)
        .sort("periods")
        .select(["periods", "so_nw_ct", "pred"])
        .to_pandas()
    )

    plt.figure(figsize=(10, 4))
    plt.plot(df_k["periods"], df_k["so_nw_ct"], label="Actual")
    plt.plot(df_k["periods"], df_k["pred"], label="LR Forecast")
    plt.xticks(rotation=45)
    plt.title(title)
    plt.legend()
    plt.tight_layout()
    plt.show()



for i, key in enumerate(top_keys_zone1, start=1):
    plot_actual_vs_lr(
        rs_lr,
        key,
        title=f"Zone 1 – Top Contributor {i} ({key})"
    )


for i, key in enumerate(top_keys_zone3, start=1):
    plot_actual_vs_lr(
        rs_lr,
        key,
        title=f"Zone 3 – Top Contributor {i} ({key})"
    )


---------------------------

df = pl.read_csv(MENTOR_FILE)

# Ensure expected columns exist
expected = {"key", "periods", "so_nw_ct", "pred"}
missing = expected - set(df.columns)
if missing:
    raise ValueError(f"Missing columns in file: {missing}")

# cast numeric columns in case they are strings
df = df.with_columns([
    pl.col("so_nw_ct").cast(pl.Float64).alias("so_nw_ct"),
    pl.col("pred").cast(pl.Float64).alias("pred")
])

# quick head and number of unique keys
print("rows:", df.shape[0])
print("unique keys:", df.select(pl.col("key")).unique().shape[0])
df.head()




# Assumes zone is the first element before underscore in key, e.g. "ZONE01_...."
df = df.with_columns(
    pl.col("key").str.split("_").list.get(0).alias("zone")
)

# show distinct zones so you can confirm naming (e.g. "ZONE01" or "ZONE1")
zones = df.select("zone").unique().to_series().to_list()
print("Distinct zones (sample):", zones[:20])




# Common zone formats seen earlier: "ZONE01" or "ZONE1".
# Adjust this list if your zone strings use a different convention.
zones_to_check = ["ZONE01", "ZONE1", "ZONE03", "ZONE3"]

# We'll pick zone strings that actually exist in the file
existing_zones = [z for z in zones_to_check if z in zones]
if not existing_zones:
    raise ValueError(f"None of the expected zone ids found in file. Distinct zones: {zones[:20]}")

# Map the "logical" zones we want to actual strings present
zone1_candidates = [z for z in existing_zones if z.startswith("ZONE0") and z.endswith("1") or z.endswith("1")]
zone3_candidates = [z for z in existing_zones if z.startswith("ZONE0") and z.endswith("3") or z.endswith("3")]

# Fallback: choose the first matching pattern
zone1 = zone1_candidates[0] if zone1_candidates else existing_zones[0]
zone3 = zone3_candidates[0] if zone3_candidates else (existing_zones[1] if len(existing_zones) > 1 else existing_zones[0])

print("Using zone1 =", zone1)
print("Using zone3 =", zone3)




def top_n_keys(df_pol, zone_value, n=3):
    agg = (
        df_pol
        .filter(pl.col("zone") == zone_value)
        .group_by("key")
        .agg(pl.col("so_nw_ct").sum().alias("total_qty"))
        .sort("total_qty", descending=True)
    )
    return agg.head(n).select("key").to_series().to_list()

top3_zone1 = top_n_keys(df, zone1, n=3)
top3_zone3 = top_n_keys(df, zone3, n=3)

print("Top 3 keys Zone1:", top3_zone1)
print("Top 3 keys Zone3:", top3_zone3)



def key_df_pandas(df_pol, key):
    # select key rows, convert periods to datetime (assumes "YYYY MM" format)
    d = df_pol.filter(pl.col("key") == key).select(["periods", "so_nw_ct", "pred"]).sort("periods").to_pandas()
    # convert periods like "2025 07" -> "2025-07-01"
    d["period_dt"] = pd.to_datetime(d["periods"].str.replace(" ", "-") + "-01", format="%Y-%m-%d", errors="coerce")
    d = d.sort_values("period_dt").reset_index(drop=True)
    return d



keys = top3_zone1
if not keys:
    print("No keys found for zone1:", zone1)
else:
    fig, axes = plt.subplots(len(keys), 1, figsize=(10, 3*len(keys)), sharex=True)
    if len(keys) == 1:
        axes = [axes]
    for ax, key in zip(axes, keys):
        d = key_df_pandas(df, key)
        if d.empty:
            ax.text(0.5, 0.5, f"No data for {key}", ha="center")
            continue
        ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual")
        ax.plot(d["period_dt"], d["pred"], marker="o", linestyle="--", label="LR pred")
        ax.set_title(f"Zone1 ({zone1}) — {key}")
        ax.set_ylabel("so_nw_ct")
        ax.legend(fontsize=8)
        ax.grid(alpha=0.2)
    plt.tight_layout()
    plt.show()




keys = top3_zone3
if not keys:
    print("No keys found for zone3:", zone3)
else:
    fig, axes = plt.subplots(len(keys), 1, figsize=(10, 3*len(keys)), sharex=True)
    if len(keys) == 1:
        axes = [axes]
    for ax, key in zip(axes, keys):
        d = key_df_pandas(df, key)
        if d.empty:
            ax.text(0.5, 0.5, f"No data for {key}", ha="center")
            continue
        ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual")
        ax.plot(d["period_dt"], d["pred"], marker="o", linestyle="--", label="LR pred")
        ax.set_title(f"Zone3 ({zone3}) — {key}")
        ax.set_ylabel("so_nw_ct")
        ax.legend(fontsize=8)
        ax.grid(alpha=0.2)
    plt.tight_layout()
    plt.show()





import numpy as np

def summary_metrics(df_p):
    # df_p must have columns: period_dt, so_nw_ct, pred
    if df_p.empty:
        return {}
    ae = np.abs(df_p["pred"] - df_p["so_nw_ct"])
    # MAPE: ignore zero actuals
    nonzero_mask = df_p["so_nw_ct"] > 0
    mape = (ae[nonzero_mask] / df_p.loc[nonzero_mask, "so_nw_ct"]) * 100
    return {
        "count": len(df_p),
        "mean_actual": df_p["so_nw_ct"].mean(),
        "mean_pred": df_p["pred"].mean(),
        "mean_abs_error": ae.mean(),
        "median_abs_error": np.median(ae),
        "mape_mean_%": mape.mean() if len(mape) else None,
        "mape_median_%": np.median(mape) if len(mape) else None
    }

print("Zone1 summaries")
for key in top3_zone1:
    d = key_df_pandas(df, key)
    print(key, summary_metrics(d))

print("\nZone3 summaries")
for key in top3_zone3:
    d = key_df_pandas(df, key)
    print(key, summary_metrics(d))









import polars as pl

df_full = pl.read_csv("mentor_lr_results.csv").with_columns([
    pl.col("so_nw_ct").cast(pl.Float64),
    pl.col("pred").cast(pl.Float64),
    pl.col("key").str.split("_").list.get(0).alias("zone"),
    pl.col("periods")
        .str.replace(" ", "-")
        .str.to_datetime("%Y-%m")
        .alias("period_dt")
])

df_full.select(["key","periods","so_nw_ct","pred"]).head()


keys_to_plot = top3_z1 + top3_z3

df_hist = (
    df_full
    .filter(pl.col("key").is_in(keys_to_plot))
    .sort(["key", "period_dt"])
)

df_hist.groupby("key").agg(
    pl.min("period_dt").alias("start"),
    pl.max("period_dt").alias("end"),
    pl.count().alias("n_periods")
)



import matplotlib.pyplot as plt
import pandas as pd

def plot_key_full_history(df_pol, key):
    d = (
        df_pol.filter(pl.col("key") == key)
              .select(["period_dt","so_nw_ct","pred"])
              .to_pandas()
              .sort_values("period_dt")
    )

    if d.empty:
        print(f"{key}: no data")
        return

    ymin = min(d["so_nw_ct"].min(), d["pred"].min())
    ymax = max(d["so_nw_ct"].max(), d["pred"].max())
    pad = (ymax - ymin) * 0.15

    fig, ax = plt.subplots(figsize=(11, 3.5))
    ax.plot(d["period_dt"], d["so_nw_ct"], label="Actual", marker="o")
    ax.plot(d["period_dt"], d["pred"], label="Prediction", linestyle="--", marker="o")

    ax.axvline(pd.to_datetime("2025-07"), color="grey", linestyle=":", label="2025-07")

    ax.set_ylim(ymin - pad, ymax + pad)
    ax.set_title(f"{key} — Full History")
    ax.legend()
    plt.show()

for k in keys_to_plot:
    plot_key_full_history(df_hist, k)









# Single cell — HISTORY (so_fcst_df) + TEST (mentor predictions) -> plot top3 zone1 & zone3 keys
import polars as pl
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

# === Config ===
MENTOR_FILE = "mentor_lr_results.csv"   # change if your mentor CSV has a different name
FORECAST_START = "2025-07-01"           # highlight from this date onward
ZONE1_PREFIX = "ZONE01"
ZONE3_PREFIX = "ZONE03"

# === 1) Load / locate full historical dataframe (so_fcst_df) ===
if "so_fcst_df" in globals():
    df_hist = so_fcst_df  # polars DF already in memory
else:
    # try to find a common CSV fallback — adjust path if you keep full data elsewhere
    fallback = Path("data/sellout_for_forecast_sample.csv")
    if fallback.exists():
        df_hist = pl.read_csv(fallback)
    else:
        raise RuntimeError("Full historical dataframe 'so_fcst_df' not found in memory and fallback CSV not found. "
                           "Load your full data into variable `so_fcst_df` or place CSV at data/sellout_for_forecast_sample.csv")

# Ensure columns exist and cast types
df_hist = df_hist.with_columns([
    pl.col("periods").cast(pl.Utf8),
    pl.col("so_nw_ct").cast(pl.Float64)
])

# If key not present in full df, construct it (matches your pipeline)
if "key" not in df_hist.columns:
    # try to create with zone_soldto_shipto_ac pattern if columns exist, otherwise expect 'key' present
    if {"zone","soldto","shipto","ac"}.issubset(set(df_hist.columns)):
        df_hist = df_hist.with_columns((pl.col("zone") + "_" + pl.col("soldto") + "_" + pl.col("shipto") + "_" + pl.col("ac")).alias("key"))
    else:
        raise RuntimeError("Full history dataframe does not contain 'key' and construction columns (zone,soldto,shipto,ac) not found.")

# parse periods into datetime column
df_hist = df_hist.with_columns(pl.col("periods").str.replace(" ", "-").str.to_datetime("%Y-%m").alias("period_dt"))

# === 2) Load mentor/test predictions (mentor file covers test horizon) ===
mentor_path = Path(MENTOR_FILE)
if not mentor_path.exists():
    raise RuntimeError(f"Mentor file not found: {MENTOR_FILE}. Place it in current dir or change MENTOR_FILE path.")
df_test = pl.read_csv(mentor_path).with_columns([
    pl.col("periods").cast(pl.Utf8),
    pl.col("so_nw_ct").cast(pl.Float64),
    pl.col("pred").cast(pl.Float64),
    pl.col("periods").str.replace(" ", "-").str.to_datetime("%Y-%m").alias("period_dt")
])

# If test lacks 'key' but can be constructed, the mentor file should already have key; otherwise error
if "key" not in df_test.columns:
    raise RuntimeError("Mentor predictions file must contain 'key' column (format: zone_soldto_shipto_ac).")

# === 3) Pick top-3 contributors per zone (use full-history 2025 totals for ranking) ===
# Use 2025 rows from history for ranking (if missing, fall back to all history)
hist_2025 = df_hist.filter(pl.col("periods").str.contains("2025"))
if hist_2025.height == 0:
    hist_for_rank = df_hist
else:
    hist_for_rank = hist_2025

def top_n_keys_for_zone(df_pol, zone_prefix, n=3):
    return (
        df_pol
        .filter(pl.col("key").str.starts_with(zone_prefix))
        .group_by("key")
        .agg(pl.col("so_nw_ct").sum().alias("total_qty"))
        .sort("total_qty", descending=True)
        .head(n)
        .select("key")
        .to_series()
        .to_list()
    )

top3_z1 = top_n_keys_for_zone(hist_for_rank, ZONE1_PREFIX, 3)
top3_z3 = top_n_keys_for_zone(hist_for_rank, ZONE3_PREFIX, 3)

keys_to_plot = top3_z1 + top3_z3
if len(keys_to_plot) == 0:
    raise RuntimeError("No keys found for the zone prefixes. Check your zone naming or content of so_fcst_df.")

print("Top keys to plot (Zone1 then Zone3):", keys_to_plot)

# === 4) Build combined timeline: history actuals + test predictions ===
# Prepare df_hist subset for keys_to_plot (include all periods available)
hist_subset = df_hist.filter(pl.col("key").is_in(keys_to_plot)).select(["key","periods","period_dt","so_nw_ct"])
# For historical rows, pred is null
hist_subset = hist_subset.with_columns(pl.lit(None).cast(pl.Float64).alias("pred"))

# Prepare test subset (only keys_to_plot)
test_subset = df_test.filter(pl.col("key").is_in(keys_to_plot)).select(["key","periods","period_dt","so_nw_ct","pred"])

# Concatenate (vertical) and sort
df_all = pl.concat([hist_subset, test_subset], how="vertical").sort(["key","period_dt"])

# === 5) Quick sanity: show start/end per key ===
print(df_all.groupby("key").agg(pl.min("period_dt").alias("start"), pl.max("period_dt").alias("end"), pl.count().alias("n_periods")).to_pandas())

# === 6) Plotting: one subplot per key, consistent y-limits within each zone group ===
import math
pd_all = df_all.to_pandas()
pd_all["period_dt"] = pd.to_datetime(pd_all["period_dt"])

# Prepare zone grouping for consistent y-limits
zone_map = {k: k.split("_",1)[0] for k in keys_to_plot}
zone_keys = {
    ZONE1_PREFIX: [k for k in keys_to_plot if k.startswith(ZONE1_PREFIX)],
    ZONE3_PREFIX: [k for k in keys_to_plot if k.startswith(ZONE3_PREFIX)]
}

# compute y-limits per zone across all keys in that zone
y_limits = {}
for zone_prefix, keys in zone_keys.items():
    if len(keys) == 0:
        continue
    subset = pd_all[pd_all["key"].isin(keys)]
    if subset.empty:
        ymin, ymax = 0, 1
    else:
        ymin = min(subset["so_nw_ct"].min(skipna=True), subset["pred"].min(skipna=True))
        ymax = max(subset["so_nw_ct"].max(skipna=True), subset["pred"].max(skipna=True))
        if np.isnan(ymin): ymin = 0
        if np.isnan(ymax): ymax = 1
    pad = (ymax - ymin) * 0.15 if ymax > ymin else max(1, ymax*0.1)
    y_limits[zone_prefix] = (ymin - pad, ymax + pad)

# Plot layout
total = len(keys_to_plot)
cols = 1
rows = total
fig, axes = plt.subplots(rows, cols, figsize=(12, 3*rows), squeeze=False)

for idx, key in enumerate(keys_to_plot):
    ax = axes[idx,0]
    d = pd_all[pd_all["key"] == key].sort_values("period_dt")
    if d.empty:
        ax.text(0.5, 0.5, f"No data for {key}", ha="center")
        continue

    # actual full history
    ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual", color="black")
    # prediction (only present for testing rows)
    # plot pred where not null
    d_pred = d[~d["pred"].isna()]
    if not d_pred.empty:
        ax.plot(d_pred["period_dt"], d_pred["pred"], marker="o", linestyle="--", label="Pred (test)")

    # vertical marker and shaded area for test period
    fs = pd.to_datetime(FORECAST_START)
    ax.axvline(fs, color="red", linestyle=":", linewidth=1)
    ax.axvspan(fs, d["period_dt"].max(), color="grey", alpha=0.08)

    # set y limits based on zone
    zone_pref = key.split("_",1)[0]
    if zone_pref in y_limits:
        ax.set_ylim(y_limits[zone_pref])

    ax.set_title(key)
    ax.set_xlabel("")
    ax.set_ylabel("so_nw_ct")
    ax.grid(alpha=0.2)
    ax.legend(fontsize=8)

plt.tight_layout()
plt.show()

# === 7) Numeric summary (for test period only) ===
print("\nNumeric summary for test period (2025-07 to 2025-12) per key:")
test_pd = pd_all[~pd_all["pred"].isna()]  # only test-period rows where pred exists
for key in keys_to_plot:
    d = test_pd[test_pd["key"]==key]
    if d.empty:
        print(f"{key}: no test rows")
        continue
    ae = np.abs(d["pred"] - d["so_nw_ct"])
    nonzero_mask = d["so_nw_ct"] > 0
    mape = (ae[nonzero_mask] / d.loc[nonzero_mask,"so_nw_ct"]) * 100 if nonzero_mask.any() else pd.Series(dtype=float)
    print(f"\n{key}")
    print(f" count test rows: {len(d)}")
    print(f" mean_actual: {d['so_nw_ct'].mean():,.1f}")
    print(f" mean_pred:   {d['pred'].mean():,.1f}")
    print(f" mean_AE:     {ae.mean():,.1f}")
    print(f" mean_MAPE%:  {mape.mean():.1f}" if len(mape)>0 else " mean_MAPE%: N/A (all actuals zero)")

