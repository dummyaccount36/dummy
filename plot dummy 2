plt.rcParams["figure.figsize"] = (12,4)
plt.rcParams["figure.dpi"] = 120

RESULTS_DIR = Path("results")


rs_rf_all = pd.read_csv(
    RESULTS_DIR / "rs_with_error_RF_all.csv"
)

rs_rf_all.head()



rs_rf_all["period_dt"] = pd.to_datetime(
    rs_rf_all["periods"].str.replace(" ", "-") + "-01",
    format="%Y-%m-%d"
)

rs_rf_all = rs_rf_all.sort_values(["key", "period_dt"])



df_k = rs_rf_all[rs_rf_all["key"] == example_key]

plt.figure()
plt.plot(df_k["period_dt"], df_k["so_nw_ct"], marker="o", label="Actual")
plt.plot(df_k["period_dt"], df_k["pred"], marker="o", linestyle="--", label="Forecast")

plt.title(f"RF Forecast vs Actual\n{example_key}")
plt.xlabel("Period")
plt.ylabel("SO Quantity")
plt.legend()
plt.tight_layout()
plt.show()







top_keys = (
    rs_rf_all[rs_rf_all["periods"].str.contains("2025")]
    .groupby("key")["so_nw_ct"]
    .sum()
    .sort_values(ascending=False)
    .head(6)
    .index
)




fig, axes = plt.subplots(3, 2, figsize=(14,9), sharex=True)
axes = axes.flatten()

for ax, key in zip(axes, top_keys):
    d = rs_rf_all[rs_rf_all["key"] == key]
    ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual")
    ax.plot(d["period_dt"], d["pred"], marker="o", linestyle="--", label="Forecast")
    ax.set_title(key)
    ax.legend(fontsize=8)

plt.tight_layout()
plt.show()






zone_keys = rs_rf_all[
    rs_rf_all["key"].str.startswith("ZONE02B")
]["key"].unique()[:4]




fig, axes = plt.subplots(2, 2, figsize=(14,7), sharex=True)
axes = axes.flatten()

for ax, key in zip(axes, zone_keys):
    d = rs_rf_all[rs_rf_all["key"] == key]
    ax.plot(d["period_dt"], d["so_nw_ct"], label="Actual")
    ax.plot(d["period_dt"], d["pred"], linestyle="--", label="Forecast")
    ax.set_title(key)
    ax.legend(fontsize=8)

plt.tight_layout()
plt.show()





plt.figure()
sns.lineplot(
    data=rs_rf_all[rs_rf_all["periods"].str.contains("2025")],
    x="period_dt",
    y="mape",
    estimator="mean"
)
plt.title("Average MAPE Over Time (RF)")
plt.ylabel("MAPE")
plt.xlabel("Period")
plt.tight_layout()
plt.show()






rs_lr_all = pd.read_csv(RESULTS_DIR / "rs_with_error_LR_all.csv")
rs_lr_all["period_dt"] = pd.to_datetime(
    rs_lr_all["periods"].str.replace(" ", "-") + "-01"
)

d_rf = rs_rf_all[rs_rf_all["key"] == example_key]
d_lr = rs_lr_all[rs_lr_all["key"] == example_key]

plt.figure()
plt.plot(d_rf["period_dt"], d_rf["so_nw_ct"], label="Actual", color="black")
plt.plot(d_rf["period_dt"], d_rf["pred"], "--", label="RF")
plt.plot(d_lr["period_dt"], d_lr["pred"], "--", label="LR")






rs_rf = pd.read_csv(RESULTS_DIR / "rs_with_error_RF_all.csv")
rs_lr = pd.read_csv(RESULTS_DIR / "rs_with_error_LR_all.csv")

# normalize column names if necessary (safe guard)
for df in (rs_rf, rs_lr):
    if "periods" not in df.columns and "period" in df.columns:
        df.rename(columns={"period":"periods"}, inplace=True)

# create period datetime
for df in (rs_rf, rs_lr):
    df["period_dt"] = pd.to_datetime(df["periods"].str.replace(" ", "-") + "-01", format="%Y-%m-%d", errors="coerce")




# remove rows where so_nw_ct is zero or NaN (these were placeholders)
rs_rf_nonzero = rs_rf[rs_rf["so_nw_ct"].notnull() & (rs_rf["so_nw_ct"] != 0)].copy()
rs_lr_nonzero = rs_lr[rs_lr["so_nw_ct"].notnull() & (rs_lr["so_nw_ct"] != 0)].copy()

# create zone column by splitting key (first element before underscore)
for df in (rs_rf_nonzero, rs_lr_nonzero):
    df["zone"] = df["key"].astype(str).str.split("_").str.get(0)




print("RF nonzero rows:", len(rs_rf_nonzero))
print("LR nonzero rows:", len(rs_lr_nonzero))

# restrict to 2025 when finding top zones (makes sense for your analysis)
rf_2025 = rs_rf_nonzero[rs_rf_nonzero["periods"].str.contains("2025", na=False)]
zone_sales = rf_2025.groupby("zone")["so_nw_ct"].sum().sort_values(ascending=False)
zone_sales.head(10)



n = 4  # change if you want more zones
top_zones = zone_sales.head(n).index.tolist()
top_zones




def agg_zone(df, model_label):
    g = df.groupby(["zone", "period_dt"], as_index=False).agg({
        "so_nw_ct": "sum",
        "pred": "sum"
    })
    g = g.rename(columns={"pred": f"pred_{model_label}", "so_nw_ct": "so_nw_ct"})
    return g

agg_rf = agg_zone(rs_rf_nonzero, "RF")
agg_lr = agg_zone(rs_lr_nonzero, "LR")

# merge RF+LR aggregates (inner join on zone+period_dt)
agg_all = agg_rf.merge(agg_lr, on=["zone", "period_dt"], how="outer", suffixes=("_rf", "_lr"))
# ensure sorted
agg_all = agg_all.sort_values(["zone", "period_dt"]).reset_index(drop=True)

# quick check
agg_all.head()




zones = top_zones   # selected zones
cols = 2
rows = int(np.ceil(len(zones) / cols))
fig, axes = plt.subplots(rows, cols, figsize=(14, 4 * rows), sharex=True)
axes = axes.flatten()

for ax_idx, zone in enumerate(zones):
    ax = axes[ax_idx]
    d = agg_all[agg_all["zone"] == zone].sort_values("period_dt")
    if d.empty:
        ax.text(0.5, 0.5, f"No data for {zone}", ha="center")
        continue
    ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual (sum)")
    ax.plot(d["period_dt"], d["pred_RF"], marker="o", linestyle="--", label="RF Pred (sum)")
    ax.set_title(zone)
    ax.set_ylabel("SO quantity (sum)")
    ax.legend(fontsize=8)
    ax.grid(alpha=0.2)

# hide unused axes
for j in range(len(zones), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()





zones = top_zones
cols = 2
rows = int(np.ceil(len(zones) / cols))
fig, axes = plt.subplots(rows, cols, figsize=(14, 4 * rows), sharex=True)
axes = axes.flatten()

for ax_idx, zone in enumerate(zones):
    ax = axes[ax_idx]
    d = agg_all[agg_all["zone"] == zone].sort_values("period_dt")
    if d.empty:
        ax.text(0.5, 0.5, f"No data for {zone}", ha="center")
        continue
    ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual (sum)", color="black")
    if "pred_RF" in d.columns:
        ax.plot(d["period_dt"], d["pred_RF"], marker="o", linestyle="--", label="RF Pred (sum)")
    if "pred_LR" in d.columns:
        ax.plot(d["period_dt"], d["pred_LR"], marker="s", linestyle=":", label="LR Pred (sum)")
    ax.set_title(zone)
    ax.set_ylabel("SO quantity (sum)")
    ax.legend(fontsize=8)
    ax.grid(alpha=0.2)

for j in range(len(zones), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()








eval_rf = rs_rf.copy()
eval_lr = rs_lr.copy()

# remove zero / padded actuals
eval_rf = eval_rf[eval_rf["so_nw_ct"] > 0]
eval_lr = eval_lr[eval_lr["so_nw_ct"] > 0]




eval_rf["mape"] = (eval_rf["ae"] / eval_rf["so_nw_ct"]) * 100
eval_lr["mape"] = (eval_lr["ae"] / eval_lr["so_nw_ct"]) * 100




plt.figure(figsize=(8,4))
plt.boxplot(
    [eval_rf["mape"], eval_lr["mape"]],
    labels=["RF", "LR"],
    showfliers=False
)
plt.ylabel("MAPE (%)")
plt.title("MAPE Distribution (Non-zero Actuals)")
plt.tight_layout()
plt.show()




for df in (eval_rf, eval_lr):
    df["zone"] = df["key"].astype(str).str.split("_").str.get(0)





zone_mape_rf = (
    eval_rf.groupby("zone")["mape"]
    .mean()
    .rename("RF")
)

zone_mape_lr = (
    eval_lr.groupby("zone")["mape"]
    .mean()
    .rename("LR")
)

zone_mape = pd.concat([zone_mape_rf, zone_mape_lr], axis=1)
zone_mape = zone_mape.sort_values("RF")
zone_mape.head(10)




zone_mape.plot(
    kind="bar",
    figsize=(12,4)
)

plt.ylabel("Average MAPE (%)")
plt.title("Average MAPE by Zone (Non-zero Actuals)")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()





rs_lr = pl.read_csv("rs_with_error_LR_all.csv")
rs_rf = pl.read_csv("rs_with_error_RF_all.csv")

rs_lr = rs_lr.filter(pl.col("periods") >= "2024 01")
rs_rf = rs_rf.filter(pl.col("periods") >= "2024 01")




candidate_keys = (
    rs_lr
    .group_by("key")
    .agg(pl.col("so_nw_ct").sum().alias("total_qty"))
    .filter(pl.col("total_qty") > 0)
    .sort("total_qty", descending=True)
)

candidate_keys.head(10)




one_zone_key = candidate_keys["key"][0]
one_zone_key




df_lr_k = (
    rs_lr
    .filter(pl.col("key") == one_zone_key)
    .select(["periods", "so_nw_ct", "pred"])
    .sort("periods")
)

df_lr_k



df_rf_k = (
    rs_rf
    .filter(pl.col("key") == one_zone_key)
    .select(["periods", "so_nw_ct", "pred"])
    .sort("periods")
)

df_rf_k





df_lr_k.select(
    pl.col("so_nw_ct").describe(),
    pl.col("pred").describe()
)



-------------------------------------------------------------------------------------------------------------------------------------------

rs_lr_1 = pl.read_csv("rs_with_error_lr.csv")
rs_lr_2 = pl.read_csv("rs_with_error_lr_2.csv")

rs_lr_1.shape, rs_lr_2.shape


rs_lr_1.select(["key", "periods"]).unique().shape, \
rs_lr_2.select(["key", "periods"]).unique().shape


stats_1 = rs_lr_1.select(pl.col("pred").describe())
stats_2 = rs_lr_2.select(pl.col("pred").describe())

stats_1, stats_2


stats_compare = (
    stats_1
    .rename({"pred": "lr_run_1"})
    .with_columns(stats_2["pred"].alias("lr_run_2"))
)

stats_compare


diff = (
    rs_lr_1
    .select(["key", "periods", "pred"])
    .join(
        rs_lr_2.select(["key", "periods", "pred"]),
        on=["key", "periods"],
        suffix="_2"
    )
    .with_columns((pl.col("pred_2") - pl.col("pred")).alias("pred_diff"))
)

diff.select(pl.col("pred_diff").describe())


-------------------------------------------------------

perf_1 = pl.read_csv("perform_lr.csv")
perf_2 = pl.read_csv("perform_lr_2.csv")



perf_1.select(pl.all().exclude(pl.Utf8)).columns


perf_1.describe(), perf_2.describe()


perf_1.select(pl.col("mape").describe()), \
perf_2.select(pl.col("mape").describe())



-------------------------------------------------------------------------------------------------------------------------------------------
rs_lr = pl.read_csv("results/rs_with_error_LR_baseline.csv")



def top_n_keys_by_zone(df, zone_id, n=3):
    return (
        df
        .filter(pl.col("zone") == zone_id)
        .group_by("key")
        .agg(pl.col("so_nw_ct").sum().alias("total_qty"))
        .sort("total_qty", descending=True)
        .head(n)
        .select("key")
        .to_series()
        .to_list()
    )


top_keys_zone1 = top_n_keys_by_zone(rs_lr, zone_id=1, n=3)
top_keys_zone3 = top_n_keys_by_zone(rs_lr, zone_id=3, n=3)

top_keys_zone1, top_keys_zone3



def plot_actual_vs_lr(df, key, title):
    df_k = (
        df
        .filter(pl.col("key") == key)
        .sort("periods")
        .select(["periods", "so_nw_ct", "pred"])
        .to_pandas()
    )

    plt.figure(figsize=(10, 4))
    plt.plot(df_k["periods"], df_k["so_nw_ct"], label="Actual")
    plt.plot(df_k["periods"], df_k["pred"], label="LR Forecast")
    plt.xticks(rotation=45)
    plt.title(title)
    plt.legend()
    plt.tight_layout()
    plt.show()



for i, key in enumerate(top_keys_zone1, start=1):
    plot_actual_vs_lr(
        rs_lr,
        key,
        title=f"Zone 1 – Top Contributor {i} ({key})"
    )


for i, key in enumerate(top_keys_zone3, start=1):
    plot_actual_vs_lr(
        rs_lr,
        key,
        title=f"Zone 3 – Top Contributor {i} ({key})"
    )


---------------------------

df = pl.read_csv(MENTOR_FILE)

# Ensure expected columns exist
expected = {"key", "periods", "so_nw_ct", "pred"}
missing = expected - set(df.columns)
if missing:
    raise ValueError(f"Missing columns in file: {missing}")

# cast numeric columns in case they are strings
df = df.with_columns([
    pl.col("so_nw_ct").cast(pl.Float64).alias("so_nw_ct"),
    pl.col("pred").cast(pl.Float64).alias("pred")
])

# quick head and number of unique keys
print("rows:", df.shape[0])
print("unique keys:", df.select(pl.col("key")).unique().shape[0])
df.head()




# Assumes zone is the first element before underscore in key, e.g. "ZONE01_...."
df = df.with_columns(
    pl.col("key").str.split("_").list.get(0).alias("zone")
)

# show distinct zones so you can confirm naming (e.g. "ZONE01" or "ZONE1")
zones = df.select("zone").unique().to_series().to_list()
print("Distinct zones (sample):", zones[:20])




# Common zone formats seen earlier: "ZONE01" or "ZONE1".
# Adjust this list if your zone strings use a different convention.
zones_to_check = ["ZONE01", "ZONE1", "ZONE03", "ZONE3"]

# We'll pick zone strings that actually exist in the file
existing_zones = [z for z in zones_to_check if z in zones]
if not existing_zones:
    raise ValueError(f"None of the expected zone ids found in file. Distinct zones: {zones[:20]}")

# Map the "logical" zones we want to actual strings present
zone1_candidates = [z for z in existing_zones if z.startswith("ZONE0") and z.endswith("1") or z.endswith("1")]
zone3_candidates = [z for z in existing_zones if z.startswith("ZONE0") and z.endswith("3") or z.endswith("3")]

# Fallback: choose the first matching pattern
zone1 = zone1_candidates[0] if zone1_candidates else existing_zones[0]
zone3 = zone3_candidates[0] if zone3_candidates else (existing_zones[1] if len(existing_zones) > 1 else existing_zones[0])

print("Using zone1 =", zone1)
print("Using zone3 =", zone3)




def top_n_keys(df_pol, zone_value, n=3):
    agg = (
        df_pol
        .filter(pl.col("zone") == zone_value)
        .group_by("key")
        .agg(pl.col("so_nw_ct").sum().alias("total_qty"))
        .sort("total_qty", descending=True)
    )
    return agg.head(n).select("key").to_series().to_list()

top3_zone1 = top_n_keys(df, zone1, n=3)
top3_zone3 = top_n_keys(df, zone3, n=3)

print("Top 3 keys Zone1:", top3_zone1)
print("Top 3 keys Zone3:", top3_zone3)



def key_df_pandas(df_pol, key):
    # select key rows, convert periods to datetime (assumes "YYYY MM" format)
    d = df_pol.filter(pl.col("key") == key).select(["periods", "so_nw_ct", "pred"]).sort("periods").to_pandas()
    # convert periods like "2025 07" -> "2025-07-01"
    d["period_dt"] = pd.to_datetime(d["periods"].str.replace(" ", "-") + "-01", format="%Y-%m-%d", errors="coerce")
    d = d.sort_values("period_dt").reset_index(drop=True)
    return d



keys = top3_zone1
if not keys:
    print("No keys found for zone1:", zone1)
else:
    fig, axes = plt.subplots(len(keys), 1, figsize=(10, 3*len(keys)), sharex=True)
    if len(keys) == 1:
        axes = [axes]
    for ax, key in zip(axes, keys):
        d = key_df_pandas(df, key)
        if d.empty:
            ax.text(0.5, 0.5, f"No data for {key}", ha="center")
            continue
        ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual")
        ax.plot(d["period_dt"], d["pred"], marker="o", linestyle="--", label="LR pred")
        ax.set_title(f"Zone1 ({zone1}) — {key}")
        ax.set_ylabel("so_nw_ct")
        ax.legend(fontsize=8)
        ax.grid(alpha=0.2)
    plt.tight_layout()
    plt.show()




keys = top3_zone3
if not keys:
    print("No keys found for zone3:", zone3)
else:
    fig, axes = plt.subplots(len(keys), 1, figsize=(10, 3*len(keys)), sharex=True)
    if len(keys) == 1:
        axes = [axes]
    for ax, key in zip(axes, keys):
        d = key_df_pandas(df, key)
        if d.empty:
            ax.text(0.5, 0.5, f"No data for {key}", ha="center")
            continue
        ax.plot(d["period_dt"], d["so_nw_ct"], marker="o", label="Actual")
        ax.plot(d["period_dt"], d["pred"], marker="o", linestyle="--", label="LR pred")
        ax.set_title(f"Zone3 ({zone3}) — {key}")
        ax.set_ylabel("so_nw_ct")
        ax.legend(fontsize=8)
        ax.grid(alpha=0.2)
    plt.tight_layout()
    plt.show()





import numpy as np

def summary_metrics(df_p):
    # df_p must have columns: period_dt, so_nw_ct, pred
    if df_p.empty:
        return {}
    ae = np.abs(df_p["pred"] - df_p["so_nw_ct"])
    # MAPE: ignore zero actuals
    nonzero_mask = df_p["so_nw_ct"] > 0
    mape = (ae[nonzero_mask] / df_p.loc[nonzero_mask, "so_nw_ct"]) * 100
    return {
        "count": len(df_p),
        "mean_actual": df_p["so_nw_ct"].mean(),
        "mean_pred": df_p["pred"].mean(),
        "mean_abs_error": ae.mean(),
        "median_abs_error": np.median(ae),
        "mape_mean_%": mape.mean() if len(mape) else None,
        "mape_median_%": np.median(mape) if len(mape) else None
    }

print("Zone1 summaries")
for key in top3_zone1:
    d = key_df_pandas(df, key)
    print(key, summary_metrics(d))

print("\nZone3 summaries")
for key in top3_zone3:
    d = key_df_pandas(df, key)
    print(key, summary_metrics(d))

